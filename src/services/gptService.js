// src/services/gptService.js
const axios = require("axios");
require("dotenv").config();
const Conversation = require("../models/Conversation");

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const FINE_TUNED_MODEL_ID = process.env.FINE_TUNED_MODEL_ID || "ft:gpt-4o-mini-2024-07-18:personal:donna-assistentepessoal:CGdyamnQ";
const FALLBACK_MODEL = "gpt-4o-mini";

// Fun√ß√£o principal
async function getGPTResponse(userMessage, imageUrl = null, userId) {
  try {
    // 1Ô∏è‚É£ Buscar hist√≥rico
    const history = await Conversation.find({ from: userId }).sort({ createdAt: 1 });

    const messages = [
      {
        role: "system",
        content: `
Voc√™ √© Donna, assistente executiva perspicaz, elegante e humanizada.
- Ajuda em administra√ß√£o, legisla√ß√£o, RH e neg√≥cios.
- Poliglota: responda no idioma da mensagem do usu√°rio.
- D√° dicas estrat√©gicas e conselhos.
- Ajuda com lembretes e compromissos.
- Responde de forma natural, personalizada e com humor ou empatia.
        `,
      },
    ];

    history.forEach(h => {
      messages.push({
        role: h.role === "assistant" ? "assistant" : "user",
        content: h.content,
      });
    });

    let userContent = userMessage || "";
    if (imageUrl) userContent += `\nüì∑ Imagem recebida: ${imageUrl}`;
    messages.push({ role: "user", content: userContent });

    console.log("üìå Mensagens a serem enviadas:", JSON.stringify(messages, null, 2));

    // 2Ô∏è‚É£ Verificar se o modelo fine-tuned existe/est√° ativo
    try {
      const modelCheck = await axios.get(
        `https://api.openai.com/v1/models/${FINE_TUNED_MODEL_ID}`,
        { headers: { Authorization: `Bearer ${OPENAI_API_KEY}` } }
      );
      console.log("‚úÖ Modelo fine-tuned encontrado:", modelCheck.data.id);
    } catch (checkError) {
      console.warn(`‚ö†Ô∏è Modelo fine-tuned n√£o encontrado ou indispon√≠vel: ${FINE_TUNED_MODEL_ID}`);
      console.warn("‚ö†Ô∏è Fallback ser√° usado automaticamente.");
    }

    // 3Ô∏è‚É£ Chamada ao fine-tuned
    try {
      const response = await axios.post(
        "https://api.openai.com/v1/chat/completions",
        { model: FINE_TUNED_MODEL_ID, messages, max_tokens: 500, temperature: 0.8 },
        { headers: { Authorization: `Bearer ${OPENAI_API_KEY}`, "Content-Type": "application/json" } }
      );

      const content = response.data.choices?.[0]?.message?.content?.trim();
      if (!content) throw new Error("Resposta vazia do modelo fine-tuned");
      console.log("‚úÖ Resposta obtida do fine-tuned");
      return content;

    } catch (ftError) {
      console.error("‚ö†Ô∏è Erro no fine-tuned:", ftError.response?.data || ftError.message);

      // 4Ô∏è‚É£ Fallback autom√°tico
      try {
        console.log("üìå Tentando fallback:", FALLBACK_MODEL);
        const fallbackResponse = await axios.post(
          "https://api.openai.com/v1/chat/completions",
          { model: FALLBACK_MODEL, messages, max_tokens: 500, temperature: 0.8 },
          { headers: { Authorization: `Bearer ${OPENAI_API_KEY}`, "Content-Type": "application/json" } }
        );

        const fallbackContent = fallbackResponse.data.choices?.[0]?.message?.content?.trim();
        if (!fallbackContent) throw new Error("Resposta vazia do fallback");
        console.log("‚úÖ Resposta obtida do fallback");
        return fallbackContent;

      } catch (fallbackError) {
        console.error("‚ùå Erro no fallback:", fallbackError.response?.data || fallbackError.message);
        return "‚ùå N√£o consegui gerar resposta com os modelos dispon√≠veis.";
      }
    }

  } catch (error) {
    console.error("‚ùå Erro geral em getGPTResponse:", error.response?.data || error.message);
    return "‚ùå Tive um problema ao processar sua mensagem.";
  }
}

module.exports = { getGPTResponse };
